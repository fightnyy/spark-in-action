# ch10 running_spark_cluster



# 10.1 스파크 런타임 아키텍처의 개요

## 10.1.1 스파크 런타임 컴포넌트

* 클라이언트
* 드라이버
* 실행자

<img src="/Users/nayeong-yun/Library/Application Support/typora-user-images/image-20211211213253979.png" alt="image-20211211213253979" style="zoom:60%;" />

> 클러스터 배포 모드로 실행한 스파크의 런타임 컴포넌트 [애플리케이션 태스크는 실행자의 태스크 슬롯에서 실행된다.[T]로 표시된 부분 흰색부분은 비어있는 태스크 슬롯이다.]

<img src="/Users/nayeong-yun/Library/Application Support/typora-user-images/image-20211212020053112.png" alt="image-20211212020053112" style="zoom:67%;" />

> 클라이언트 배포 모드로 실행한 스파크 런타임 컴포넌트 (드라이버를 클라이언트의 JVM 프로세스에서 실행함)



### 10.1.1.1 클라이언트 프로세스의 역할

* 드라이버 프로그램을 시작한다.

### 10.1.1.2 드라이버의 역할

* 스파크 애플리케이션의 실행을 관장하고 모니터링한다.
* 하나의 스파크 애플리케이션에는 하나의 드라이버만 존재한다.
* 드라이버 프로그램은 두가지 방법으로 실행할 수 있다.
  * 클러스터 배포 모드
    * 드라이버 프로세스를 클러스터 내부에서 별도의 JVM 프로세스로 실행하고 드라이버 프로세스의 리소스를 클러스터가 관리한다. 
  * 클라이언트 배포 모드
    * 드라이버를 클라이언트의 JVM 프로세스에서 실행한다.

### 10.1.1.3 실행자의 역할

* 드라이버가 요청한 태스크들을 받아서 실행함
* 결과는 드라이버로 반환함
* 태스크들을 여러 태스크 슬롯에서 병렬로 실행함
* 태스크 슬롯의 개수는 CPU 코어 개수의 두세배 정도로 설정한다.
  * 태스크 슬롯은 스레드로 구현되므로 머신의 물리적인 CPU 코어 개수와 일치할 필요는 없다.

### 10.1.1.4 스파크 컨텍스트의 생성

* 드라이버는 `SparkContext` 인스턴스를 생성하고 시작한다.
* 스파크 컨텍스트는 JVM 당 하나만 생성할 수 있다.
  * `spark.driver.allowMultipleContexts` 라는 항목으로 여러개의 스파크 컨텍스트를 사용할 수도 있지만 이는 권장하지 않는다.
  * 예기치 않은 에러가 발생할 수도 있다.



## 10.1.2 스파크 클러스터 유형

* 스파크는 로컬모드, yarn 클러스터, 메소스 클러스터, 자체 클러스터 등으로 실행할 수 있다.

### 10.1.2.1 스파크 자체 클러스터

* 스파크 전용 클러스터다.
* 스파크 애플리케이션에만 적합하게 설계되었기 때문에 켈베로스 인증 프로토콜로 보호된 HDFS를 지원하지 않는다.
* 이와 같은 보안이 필요하면 YARN을 사용해 스파크를 실행해야 한다.
* 단, 잡 시작에 걸리는 시간은 YARN 보다 짧다.



### 10.1.2.2 YARN 클러스터

* 하둡의 리소스 매니저 및 작업 실행 시스템으로 맵리듀스 버전 2라고도 한다.
* 이미 많은 조직들이 YARN을 이용해서 클러스터를 구축해 노하우 등이 많이 나와있다.
* 자바 앱도 실행할 수 있다.
* 켈베로스 기반의 보안 HDFS 는 YARN에서만 지원



### 10.1.2.3 메소스 클러스터

* 확장성과 장애 내성을 갖춘 C++ 기반 분산 시스템 커널
* C++ 과 파이썬 애플리케이션을 지원
* 다른 클러스터에서 지원하지 않는 다양한 추가 옵션을 제공한다.
* YARN에서는 Myriad 프로젝트를 사용하면 YARN을 메소스 형태로 실행할 수 있다고 한다.



### 10.1.2.4 스파크 로컬 모드

* 테스트용, 운영환경으로는 사용할 수 없다.

# 10.2 잡 스케줄링과 리소스 스케줄링

* 클러스터 매니저와 스파크 스케줄러는 스파크 잡을 실행하는데 필요한 리소스를 부여한다.
* 클러스터 리소스 스케줄링
  * 여러 스파크 애플리케이션의 실행자에 리소스를 할당한다.
* 스파크 리소스 스케줄링
  * 단일 스파크 애플리케이션 내에서 태스크를 실행할 CPU 및 메모리 리소스를 스케줄링한다.



## 10.2.1 클러스터 리소스 스케줄링

* 단일 클러스터에서 실행하는 다수의 애플리케이션에 클러스터의 리소스를 나눠 주는 작업은 클러스터 매니저가 담당.
* 클러스터가 리소스를 스케줄링하는 방식은 스파크가 지원하는 모든 클러스터 유형에서 유사하지만 세세한 차이점들이 존재



## 10.2.2 스파크 잡 스케줄링

* 스파크 자체에서 수행하는 작업으로, 잡을 어떻게 태스크로 분할하고 어떤 실행자에 전달할지 결정하는 작업.
* 스파크는 CPU 리소스를 분배하는 방식으로 선입선출 스케줄링, 공정 스케줄링 모드를 지우너한다.



### 10.2.2.1 선입선출 스케줄러

* 가장 먼저 리소스를 요청한 잡이 모든 실행자의 테스크 슬롯을 필요한 만큼 차지한다.

  <img src="/Users/nayeong-yun/Library/Application Support/typora-user-images/image-20211212022759563.png" alt="image-20211212022759563" style="zoom:50%;" />

> 드라이버는 잡 2개로 구성되어있고 1번잡을 실행하기 위해선 15개의 태스크를 실행해야 하고, 그중 12개의 태스크를 실행하는 중이다. 2번잡은 6개의 태스크만 사용하면 되지만 1번이 먼저 리소스를 요청해서 대기중이다.

* 스파크의 기본 스케줄링 모드이며, 한번에 잡 하나만 실행하는 단일 사용자 애플리케이션에 적합하다.



### 10.2.2.2 공정 스케줄러

* 실행자 리소스를 놓고 경쟁하는 스파크 잡들에 라운드로빈방식으로 균등하게 리소스를 분배한다.

  <img src="/Users/nayeong-yun/Library/Application Support/typora-user-images/image-20211212024309798.png" alt="image-20211212024309798" style="zoom:50%;" />

> 잡 두개와 실행자 두개로 구성된 공정 스케줄링 모드(1번잡이 먼저 리소스를 요청 했지만 1번 잡과 2번잡의 태스크가 병렬로 실행될 수 있다.)





### 10.2.2.3 태스크 예비 실행

* 다른 프로세스가 일부 실행자 프로세스의 CPU 리소스를 모두 점유할 때 해당 실행자는 태스크를 제시간에 완수하지 못할 수 있다 .
* 이때 예비 실행기능 사용시 스파크는 해당 파티션 데이터를 처리하는 동일한 태스크를 다른 실행자에도 요청한다.
* 하지만 일부 작업엔 예비실행 사용하는것이 적절치 않음
  * RDMBS와 같은 외부시스템에 데이터를 내보내는 작업
  * 모든 스파크 설정을 제어할 수 있는 전체권한이 없을 때





## 10.2.3 데이터 지역성

* 스파크가 데이터와 최대한 가까운 위치에서 태스크를 실행하려고 하는것
* 한 노드의 데이터를 다른 노드가 처리하면 안될 때만 해당 변수의 크게 설정해야 한다.



## 10.2.4 스파크의 메모리 스케줄링



### 10.2.4.1 클러스터 매니저가 관리하는 메모리

<img src="/Users/nayeong-yun/Library/Application Support/typora-user-images/image-20211212130312412.png" alt="image-20211212130312412" style="zoom:50%;" />

* 스파크 1.5.2 이하 버전에서는 셔플링 메모리와 캐스 스토리지 메모리가 분리되어 메모리를 충분히 활용할 수 없다는 문제점이 있었다.
* 하지만 1.6 버전부터는 실행 메모리영역과 스토리지 메모리 영역을 통합해 관리한다.
* 1.6.0 버전에서 메모리가 분리되었던 기능을 사용하고 싶으면 `spark.memory.useLegacyMode` 를 `true` 로 설정하면 된다.





### 10.2.4.3 드라이버 메모리 설정

* 드라이버의 메모리 리소스는 `spark.driver.memory` 매개변수로 설정한다. 
* 단, 클라이언트모드에서는 드라이버가 외부 애플리케이션의 메모리 중 일부를 사용한다.
* 즉, 드라이버의 메모리 공간을 늘리려면 자바의 `-Xmx` 옵션을 사용해 자바힙의 최대크기를 늘려야 한다.





# 10.3 스파크 설정



## 10.3.1 스파크 환경 설정 파일

* 스파크 환경 매개변수의 기본값은 `SPARK_HOME/conf/spark-defaults.conf` 파일에 지정한다.
* 별도의 환경 설정파일을 지정하려면 `--properties-file` 명령줄 매개변수로 파일 경로를 변경해야 한다.



## 10.3.2 명령줄 매개변수

* `spark-shell` 이나 `spark-submit` 명령에 인수를 지정하고 애플리케이션을 설정할 수 있다.

* 참고로 명령줄 매개변수와 환경설정 파일의 매개변수는 동일 변수라도 이름이 서로 다르다.

  ```shell
  spark-shell --driver-memory 16g
  spark-shell --conf spark.driver.memory=16g
  ```

## 10.3.3 시스템 환경 변수

* 환경 매개변수중 일부는 `SPARK_HOME/conf`  디렉터리 아래에 있는 `spark-env.sh` 파일로 지정할 수 있다.
* 시스템 환경변수로 설정한 값은 모든 설정 방식중 가장 낮은 우선순위로 적용된다.



## 10.3.4 프로그램 코드로 환경설정

```scala
val conf = new org.apache.spark.SparkConf()
conf.set("spark.driver.memory", 16g)
val sc = new org.apache.spark.SparkContext(conf)
```

* 가장 우선순위가 높다.
* 반드시 `SparkContext` 객체를 생성하기 전에 `SparkConf` 객체의 설정을 마쳐야 한다.



## 10.3.5 master 매개변수

* `master` 매개 변수는 애플리케이션을 실행할 스파크 클러스터 유형을 지정한다.

  ```
  shell
  spark-submit --master <master_connection_url> 
  
  scala
  val conf = org.apache.spark.SparkConf()
  conf.set("spark.master", "<master_connection_url>")
  
  or
  
  conf.setMaster("<master_connection_url>")
  ```



## 10.3.6 설정된 매개변수 조회

`sc.getConf.getAll` 메서드를 호출해 스파크 컨텍스트에 명시적으로 정의 및 로드된 모든 환경 매개변수목록을 가져올 수 있다.

# 10.4 잡 스케줄링과 리소스 스케줄링

* 스파크는 SparkContext를 생성하면 동시에 스파크 웹 UI를 시작한다.
* 스파크 독립형 애플리케이션에서는 SparkConf 객체의 `setName` 메서도로 스파크 웹 UI에 표시된 애플리케이션 이름을 변경할 수 있다.
* 또는 `spark-submit` 명령에 `--conf spark.app.name = <new_name>` 을 지정해 변경할 수 있다.
* 하지만 스파크 쉘 에서는 변경할 수 없다.

# 10.5 로컬 머신에서 스파크 실행

* 로컬 런다임 모드는 두가지가 있다.
  1. 로컬모드
  2. 로컬 클러스터 모드



## 10.5.1 로컬 모드

* 대용량 클러스터에 접속할 권한이 없거나 간단한 아이디어 및 프로그램을 빠르게 테스트할 때 유용하다.

  <img src="/Users/nayeong-yun/Library/Application Support/typora-user-images/image-20211212143150916.png" alt="image-20211212143150916" style="zoom:50%;" />

  > 로컬모드에서의 런타임 아키텍쳐

* 클라이언트 프로세스를 마치 클러스터의 단일 실행자 처럼 사용하며, master 매개변수에 지정된 스레드 개수는 곧 병렬 태스크 개수를 의미한다.
* 최적의 스레드 개수는 통상적으로 CPU 코어 개수의 두세배로 설정한다.
* 스파크 로컬 모드를 실행하려면 master 매개변수 값을 다음 중 하나로 지정해야한다.
  * `local[<n>]`:  스레드 <n> 개를 사용해 단일 실행자를 실행한다. <n> 에는 양의 정수를 지정해야함(local == local[1])
  * `local[*]` : 모든 CPU 코어를 전부 사용한다. 



## 10.5.2 로컬 클러스터 모드

* 스파크 내부 테스트용
* 로컬 클러스터 모드로 시작하기 위해선 `master` 매개변수에 `local-cluster[<n>, <c>, <m>]` 을 입력해야 한다.
  * <n> 실행자의 개수
  * <c> 스레드의 개수
  * <m> m MB 메모리를 사용하는 실행자